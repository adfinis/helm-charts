# Default values for timed-chart.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.
backend:
  # backend.replicaCount -- (int) Number of Backend replicas
  replicaCount: 1
  image:
    # backend.image.repository -- Backend image name
    repository: adfinissygroup/timed-backend
     # Specify a tag to override which version of timed to deploy.
     # If no tag is specified the appVersion from Chart.yaml is used as tag.
    # backend.image.tag -- Backend image tag
    tag: v1.3.0
    # backend.image.pullPolicy -- Backend image pull policy
    pullPolicy: IfNotPresent
  service:
    # Specifiy secret for authentication.
    # If not random token will be generated
    # secret:
    # backend.service.name -- Backend service name
    name: timed-backend
    # backend.service.type -- Backend service type
    type: ClusterIP
    # backend.service.externalPort -- External Port of backend service
    externalPort: 80
    # backend.service.internalPort -- Internal Port of backend service
    internalPort: 80
  # backend.resources -- Resource limits for backend
  resources: {}
    # We usually recommend not to specify default resources and to leave this as a conscious
    # choice for the user. This also increases chances charts run on environments with little
    # resources, such as Minikube. If you do want to specify resources, uncomment the following
    # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
    # limits:
    #  cpu: 100m
    #  memory: 128Mi
    # requests:
    #  cpu: 100m
    #  memory: 128Mi
  livenessProbe:
    # backend.livenessProbe.enabled -- Enable liveness probe on backend
    enabled: true
    # backend.livenessProbe.initialDelaySeconds -- Number of seconds after the container has started before liveness probe is initiated
    initialDelaySeconds: 60
    # backend.livenessProbe.periodSeconds -- How often (in seconds) to perform the probe
    periodSeconds: 10
    # backend.livenessProbe.timeoutSeconds -- Number of seconds after which the probe times out
    timeoutSeconds: 5
    # backend.livenessProbe.failureThreshold -- Number of tries to perform the probe
    failureThreshold: 6
    # backend.livenessProbe.successThreshold -- Minimum consecutive successes for the probe to be considered successful after having failed
    successThreshold: 1
  readinessProbe:
    # backend.readinessProbe.enabled -- Enable readiness probe on backend
    enabled: true
    # backend.readinessProbe.initialDelaySeconds -- Number of seconds after the container has started before readiness probe is initiated
    initialDelaySeconds: 30
    # backend.readinessProbe.periodSeconds -- How often (in seconds) to perform the probe
    periodSeconds: 10
    # backend.readinessProbe.timeoutSeconds -- Number of seconds after which the probe times out
    timeoutSeconds: 5
    # backend.readinessProbe.failureThreshold -- Number of tries to perform the probe
    failureThreshold: 6
    # backend.readinessProbe.successThreshold -- Minimum consecutive successes for the probe to be considered successful after having failed
    successThreshold: 1
  settings:
    # django settings for backend
    # backend.settings.emailUrl -- Connection string of SMTP server to send mails
    emailUrl: smtp://localhost:25
    # backend.settings.emailFrom -- Default email address to use for various responses
    emailFrom: webmaster@chart-example.local
    # backend.settings.serverEmail -- Email address error messages are sent from
    serverEmail: webmaster@chart-example.local
    # backend.settings.workReportPath -- Path where the workreport shall be loaded from. The contents of the default path is filled from `configmap-workreport.yaml`.
    workReportPath: /etc/workreport
    # backend.settings.admins -- Django administrators, example: Jon Doe <jon.doe@example.com>
    admins: []
    gunicorn:
      # backend.settings.gunicorn.workers -- Number of gunicorn workers
      workers: 8
      # backend.settings.gunicorn.cmdArgs -- gunicorn additional arguments
      cmdArgs: ""
    sentry:
      # backend.settings.sentry.enabled -- Enable Sentry integration
      enabled: false
      # backend.settings.sentry.dsn -- Sentry DSN for error reporting. Set to enable Sentry integration
      dsn: ~
      # backend.settings.sentry.tracesSampleRate -- Sentry trace sample rate, Set 1.0 to capture 100% of transactions
      tracesSampleRate: 1.0
      # backend.settings.sentry.sendDefaultPii -- Associate users to errors in Sentry
      sendDefaultPii: "True"


  cronjobs:
    # backend.cronjobs.notifySupervisors -- Notify supervisors
    notifySupervisors:
      schedule: "0 8 * * 4"
      command:
        - "./manage.py"
        - "notify_supervisors_shorttime"
    # backend.cronjobs.notifyReviewersFirst -- Notify reviewers first stage
    notifyReviewersFirst:
      schedule: "0 8 4 * *"
      command:
        - "./manage.py"
        - "notify_reviewers_unverified"
        - "--offset"
        # backend.cronjobs.notifyReviewersFirst.command[3] -- Period will end today minus given offset
        - "5"
    # backend.cronjobs.notifyReviewersSecond -- Notify reviewers second stage
    notifyReviewersSecond:
      schedule: "0 8 11 * *"
      command:
        - "./manage.py"
        - "notify_reviewers_unverified"
        - "--offset"
        # backend.cronjobs.notifyReviewersSecond.command[3] -- Period will end today minus given offset
        - "12"
        - "--message"
        # backend.cronjobs.notifyReviewersSecond.command[5] -- Additional message to send if there are unverified reports
        - "'Please verify your reports.'"
    # backend.cronjobs.notifyReviewersThird -- Notify reviewers third stage
    notifyReviewersThird:
      schedule: "0 8 18 * *"
      command:
        - "./manage.py"
        - "notify_reviewers_unverified"
        - "--offset"
        # backend.cronjobs.notifyReviewersThird.command[3] -- Period will end today minus given offset
        - "19"
        - "--message"
        # backend.cronjobs.notifyReviewersThird.command[5] -- Additional message to send if there are unverified reports
        - "'Please verify your reports immediately!'"
    # backend.cronjobs.redmineReport -- Redmine report
    redmineReport:
      schedule: "0 1 * * 1"
      command:
        - "./manage.py"
        - "redmine_report"
    # backend.cronjobs.notifyChangedEmployments -- Notify changed employments
    notifyChangedEmployments:
      schedule: "0 2 * * 1"
      command:
        - "./manage.py"
        - "notify_changed_employments"

frontend:
  # frontend.replicaCount -- (int) Number of Backend replicas
  replicaCount: 1
  image:
    # frontend.image.repository -- Frontend image name
    repository: adfinissygroup/timed-frontend
    # Specify a tag to override which version of timed to deploy.
    # If no tag is specified the appVersion from Chart.yaml is used as tag.
    # tag:
    # frontend.image.pullPolicy -- Frontend image pull policy
    pullPolicy: IfNotPresent
    # frontend.image.tag -- Frontend version (optional) in case it differs from backend
    tag: v1.3.1
  service:
    # frontend.service.name -- Frontend service name
    name: timed-frontend
    # frontend.service.type -- Frontend service type
    type: ClusterIP
    # frontend.service.externalPort -- External Port of frontend service
    externalPort: 80
    # frontend.service.internalPort -- Internal Port of frontend service
    internalPort: 80
  # frontend.resources -- Resource limits for frontend
  resources: {}
    # We usually recommend not to specify default resources and to leave this as a conscious
    # choice for the user. This also increases chances charts run on environments with little
    # resources, such as Minikube. If you do want to specify resources, uncomment the following
    # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
    # limits:
    #  cpu: 100m
    #  memory: 128Mi
    # requests:
    #  cpu: 100m
    #  memory: 128Mi
  livenessProbe:
    # frontend.livenessProbe.enabled -- Enable liveness probe on frontend
    enabled: true
    # frontend.livenessProbe.initialDelaySeconds -- Number of seconds after the container has started before liveness probe is initiated
    initialDelaySeconds: 60
    # frontend.livenessProbe.periodSeconds -- How often (in seconds) to perform the probe
    periodSeconds: 10
    # frontend.livenessProbe.timeoutSeconds -- Number of seconds after which the probe times out
    timeoutSeconds: 5
    # frontend.livenessProbe.failureThreshold -- Number of tries to perform the probe
    failureThreshold: 6
    # frontend.livenessProbe.successThreshold -- Minimum consecutive successes for the probe to be considered successful after having failed
    successThreshold: 1
  readinessProbe:
    # frontend.readinessProbe.enabled -- Enable readiness probe on frontend
    enabled: true
    # frontend.readinessProbe.initialDelaySeconds -- Number of seconds after the container has started before readiness probe is initiated
    initialDelaySeconds: 30
    # frontend.readinessProbe.periodSeconds -- How often (in seconds) to perform the probe
    periodSeconds: 10
    # frontend.readinessProbe.timeoutSeconds -- Number of seconds after which the probe times out
    timeoutSeconds: 5
    # frontend.readinessProbe.failureThreshold -- Number of tries to perform the probe
    failureThreshold: 6
    # frontend.readinessProbe.successThreshold -- Minimum consecutive successes for the probe to be considered successful after having failed
    successThreshold: 1

ingress:
  # ingress.enabled -- Enable ingress for timed
  enabled: false
  # ingress.annotations -- Ingress annotations
  annotations: {}
    # kubernetes.io/ingress.class: nginx
    # kubernetes.io/tls-acme: "true"
  # ingress.hosts -- Ingress hostnames
  hosts: []
  #  - timed-test.example.com
  # ingress.tls -- Ingress TLS options
  tls: []
  #  - secretName: chart-example-tls
  #    hosts:
  #      - timed-test.example.com

postgresql:
  # postgresql.enabled -- Enable PostgreSQL for persistence
  enabled: true
  # postgresql.postgresqlDatabase -- PostgreSQL database name
  postgresqlDatabase: timed
  # postgresql.postgresqlUsername -- PostgreSQL user name
  postgresqlUsername: postgres
  # postgresql.postgresqlPassword -- Set a password for PostgreSQL
  # postgresqlPassword: s3cr3t
  image:
    # Use Postgresql 12
    # postgresql.image.tag -- PostgreSQL image version to use
    tag: 12.3.0
  ingress:
    # postgresql.ingress.enabled -- Enable ingress
    enabled: false
    # postgresql.ingress.loadBalancerSourceRanges -- Whitelist specific IP ranges
    loadBalancerSourceRanges: []
    # postgresql.ingress.selector -- Service selector labels
    selector:
      app.kubernetes.io/name: postgresql
      role: slave
  tls:
    # postgresql.tls.enabled -- Enable TLS for Postgresql
    enabled: false
    # postgresql.tls.certificatesSecret -- Name of TLS secret
    certificatesSecret: psql-server
    # postgresql.tls.certFilename -- Cert file name
    certFilename: "tls.crt"
    # postgresql.tls.certKeyFilename -- Cert key filename
    certKeyFilename: "tls.key"
    certificate:
      # postgresql.tls.certificate.name -- Name of certificate
      name: psql-server
      # postgresql.tls.certificate.dnsNames -- DNS names of certificate
      dnsNames: []
      # postgresql.tls.certificate.issuerRef -- Issuer ref
      # @default -- cert-manager
      issuerRef:
        group: cert-manager.io
        kind: ClusterIssuer
        name: letsencrypt-prod

auth:
  # auth.allowLocalLogin -- Allow local Django login
  allowLocalLogin: "False"
  oidc:
    # auth.oidc.host -- OIDC host
    url: https://example.com/auth/realms/timed/protocol/openid-connect
    endPoints:
      # auth.oidc.endPoints.auth -- OIDC /auth endpoint
      auth: ~
      # auth.oidc.endPoints.token -- OIDC /token endpoint
      token: ~
      # auth.oidc.endPoints.userInfo -- OIDC /userinfo endpoint
      userInfo: ~
      # auth.oidc.endPoints.jwks -- OIDC /certs endpoint
      jwks: ~

    # auth.oidc.createUser -- OIDC create user in timed db if it does not already exist
    createUser: "False"
    # auth.oidc.adminLoginRedirectUrl -- URL of the django-admin, to which the user is redirected after successful admin login
    adminLoginRedirectUrl: https://example.com/admin/
    client:
      # auth.oidc.client.id -- OIDC client id
      id: timed
    # auth.oidc.signAlgorithm -- Algorithm the OIDC provider uses to sign ID tokens
    signAlgorithm: RS256
    # auth.oidc.verifySSL -- OIDC verify SSL
    verifySSL: "True"
    introspect:
      # auth.oidc.introspect.enabled -- Enable OIDC introspect
      enabled: true
      client:
        # auth.oidc.introspect.client.id -- OIDC introspect client id
        id: timed-confidential
        # auth.oidc.introspect.client.secret -- OIDC introspect client secret
        secret: ~
      # auth.oidc.introspect.endpoint -- OIDC introspect endpoint
      endpoint: ~
    claims:
      # auth.oidc.claims.firstname -- OIDC firstname claim name
      firstname: given_name
      # auth.oidc.claims.lastname -- OIDC lastname claim name
      lastname: family_name
      # auth.oidc.claims.username -- OIDC username claim name
      username: preferred_username
      # auth.oidc.claims.email -- OIDC email claim name
      email: email

redmine:
  # redmine.enabled -- Enable Redmine integration
  enabled: false
  # redmine.url -- Redmine URL
  url: redmine.example.com
  # redmine.apiKey -- Redmine API Key
  apiKey: ""
  # redmine.spenthoursField -- Spent hours field id on Redmine
  spenthoursField: 0

prometheus:
  # prometheus.enabled -- Enable Prometheus integration
  enabled: false
  # prometheus.extraLabels -- Labels to add to all Prometheus integration resources
  extraLabels: {}
  podMonitor:
    # prometheus.podMonitor.enabled -- Enable creation of a PodMonitor CRD
    enabled: true
    # prometheus.podMonitor.interval -- Interval at which metrics should be scraped
    interval: "30s"
    # prometheus.podMonitor.metricRelabelings -- MetricRelabelConfigs to apply to samples before ingestion
    metricRelabelings: []
    # prometheus.podMonitor.relabelings -- RelabelConfigs to apply to samples before scraping
    relabelings: []

# Configure if timed should be deployed with Grafana templates
grafana:
  # grafana.enabled -- Enable Grafana Dashboards
  enabled: false
  # grafana.defaultLabel -- Add a default `grafana_dashboard: 1` label
  defaultLabel: true
  # grafana.extraLabels -- Labels to add to all Grafana integration resources
  extraLabels: {}
